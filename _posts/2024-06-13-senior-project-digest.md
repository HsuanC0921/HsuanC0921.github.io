---
layout: post
title:  "大學畢業資訊專題報告精簡版"
date:   2024-06-13 15:25:30 +0800
categories: 教育, 技術, AI
---
本網頁內容為我為了大學畢業製作的資訊專題報告的內容的的精簡版本。
因為沒有參加資訊專題競賽，故將報告內容摘要（當然還有原檔和影片等）公開於此網站，以供任何人閱覽。

## 摘要

自2022年11月OpenAI推出ChatGPT以來，大型語言模型在自然語言處理和人工智慧領域的重要性日益突顯。眾多公司和研究機構紛紛投入資源，培訓具有巨大參數量和先進深度學習技術的LLM，這些模型在理解和生成自然語言方面取得了顯著的成就，並已廣泛應用於各個領域。

在這一背景下我開始了這項專題研究，本專題最初旨在對Mistral AI公司的Mistral 7B模型（擁有70億+參數）進行中文微調以便更好地適應中文語境，滿足多樣化應用需求。然而面對微調大量資料的高昂成本和硬體資源的限制（沒有經費），我不得不調整研究方向。儘管考慮過使用Google Colab的硬體資源進行微調，但微調一個模型仍需耗費大量時間，加之A100 GPU的租用成本過高，我最終還是決定修改目標。

我轉而將研究目標改為建立一個理解中文的程式助手，其功能類似於GitHub Copilot，（但不必能用流暢以中文回答，只要能夠理解中文就好）。在這一過程中，我從數十組不同的LLM中挑選了聯發科的Breeze和民間研發的Dolphin兩個7B模型進行實驗，這兩個模型均源自Mistral 7B的微調版本。經過參數合併和調整，我獲得了滿意的結果。

為了方便驗證和應用研究成果，我將微調後的模型部署在Oracle Free Tier免費伺服器上。儘管借助許多技術，大型語言模型也能在低資源環境下執行，但在本地執行多少會拖累到日常作業。因此為了提供一個輕鬆且便捷的即問即答體驗，我認為將模型部署在雲端環境是更符合研究目標的做法。

這項專題研究雖然只是我個人的小規模嘗試，但我希望它能夠激勵更多人參與到開源大型語言模型的研究中，從而推動語言處理技術的發展和進步。

## 1. 緒論

### 1.1 研究背景與動機

受到OpenAI的ChatGPT的啟發，我原先計畫開發一個AI聊天APP，但考量到OpenAI的收費模式和專題主題的時效性，我決定轉向研究自行架設伺服器或在本機端執行大型語言模型（LLM）。我認為自行建立LLM是一個更低成本且開源開放的替代方案，尤其在llama.cpp的出現讓LLM可以在CPU上輕鬆執行，甚至能在行動裝置上運作。

###  1.2 研究目的

本研究最初的目標是對Mistral AI公司的Mistral 7B模型進行中文微調，但由於微調需要大量的中文語料和硬體資源的限制，我將目標調整為建立一個能理解中文的程式助手。透過合併聯發科的Breeze模型和民間研發的Dolphin模型，期望能結合兩者的優勢，打造一個兼具中文理解和程式設計能力的模型。


###  1.3 研究範圍與限制

由於缺乏足夠的資源和硬體裝置，本研究無法從零開始訓練新的LLM，也難以對現有模型進行大規模微調。因此，研究範圍主要集中在選擇和合併現有的開源LLM，並測試其在中文理解和程式設計方面的能力。

本研究在微調模型的過程中也遇到了一些困難，例如LLM只能吸收片面的內容，針對特定問題的回答可能出現胡言亂語，甚至可能降低模型的整體回答能力。


## 2. 文獻探討（含相關研究）

### 2.1 大型語言模型的概述

大型語言模型（LLM）是一種基於大量文字資料進行訓練的人工神經網路（ANN）模型。LLM 具有數十億甚至數千億個參數，能夠捕捉語言中的複雜模式和關係，並生成類似人類的文字。


#### 2.1.1 LLM的發展歷史

LLM 的發展可以追溯到 20 世紀 50 年代的自然語言處理（NLP）研究，但早期模型規模較小，效果不理想。2017 年，Google AI 團隊發表的 Transformer 模型，採用注意力機制，大幅提升了模型在機器翻譯等任務上的表現。2020 年，OpenAI 推出的 GPT-3 模型，擁有 1750 億個參數，是當時最大的 LLM 模型，在多種 NLP 任務中表現出色。

#### 2.1.2 LLM主要涉及的技術

LLM 的訓練通常採用自監督學習或半監督學習方法。自監督學習利用未標記的文字資料，讓模型學習資料中的統計規律。半監督學習則結合少量標記資料和大量未標記資料，進一步提高模型效能。

#### 2.1.3 LLM的應用

LLM 在 NLP 和 AI 領域有廣泛應用，包括機器翻譯、文字摘要、問答系統、自然語言生成、情感分析、人機互動、虛擬助手和內容創作等。

### 2.2 大型語言模型的微調與合併

#### 2.2.1 大型語言模型微調

LLM 通常使用大量通用文字資料進行訓練，但在特定領域應用中，可能需要根據特定需求進行調整，這就需要對 LLM 進行微調。微調是使用特定領域的資料對 LLM 進行再訓練，以提高其在特定領域的效能。微調的方法包括全參數微調和部分參數微調，前者效果更好但需要更多資源，後者則更節省資源。常用的微調技術包括資料增強、學習率退火和梯度裁剪。微調可以提高模型效能、減少訓練資料量、加快訓練速度，並應用於機器翻譯、文字摘要、問答系統和聊天機器人等場景。

#### 2.2.2 大型語言模型合併

大型語言模型合併是將兩個或多個 LLM 組合成一個新的 LLM。新模型可以繼承合併前各個 LLM 的優點，並在特定領域表現更佳。主要技術包括參數平均和知識蒸餾。合併可以提高模型效能、減少模型規模、提高模型強健性，並應用於多個場景，如提高特定領域效能、建立專家模型和減少模型規模。

### 2.3 大型語言模型的架構和訓練方法

#### 2.3.1 大型語言模型的架構

大型語言模型通常採用 Transformer 架構，由編碼器和解碼器組成，兩者都由多個自注意力層構成。自注意力層使模型能學習輸入序列中不同部分間的關係。

#### 2.3.2 大型語言模型的訓練方法

訓練分為預訓練和微調兩個階段。預訓練在大量未標記文字上進行自監督或半監督學習，任務包括下一個單字預測、句子重建和掩碼語言建模。微調則在特定任務的標記資料集上進行監督學習。

### 2.4 基於LLM的程式助手的研究

程式助手是一種基於LLM技術，能幫助程式設計師提高效率的工具。它可以根據輸入自動補全程式碼、生成測試用例、重構程式碼等。主流程式助手採用基於LLM的技術，透過學習大量程式碼來掌握編寫規律，提供更準確、智慧的程式碼補全功能。GitHub Copilot是最受歡迎的程式助手之一，採用GPT-3語言模型。基於LLM的程式助手優點是準確性高、智慧性強、功能豐富，但也面臨訓練資料品質和安全性方面的挑戰。

### 2.5 基於LLM的程式助手的評估標準

Human-Eval 和 MBPP 是兩種主流的 LLM 程式助手的程式能力評估標準，都是由人工撰寫的 Python 程式設計問題組成，用於測試語言模型生成程式碼的能力和正確性。Human-Eval 由 OpenAI 推出，有 164 個較難的問題，涵蓋範圍廣，測試模型在複雜任務中的表現。MBPP 由 Google 推出，有約 1000 個較簡單的問題，涵蓋範圍窄，測試模型在基礎任務中的表現。兩者都是基於 Python、自然文字、人工撰寫和測試的，具有互補性，結合兩者的評估結果，可以更全面地判斷 LLM 程式助手的程式水平。

## 3. 系統設計與實作

### 3.1 系統架構設計

本系統旨在打造一個能理解中文指令並生成程式碼的助手。為此，我合併了兩個大型語言模型（LLM）：聯發科實驗室開發的Breeze 7B-Instruct-v1_0，擅長繁體中文理解，以及Cognitive Computation的Dolphin 2.6 Mistral 7b - DPO Laser，擅長程式設計和數學推理。這兩個模型都源自Mistral 7B，具有相同的架構，方便合併。

#### 3.1.1 合併模型概述

Breeze模型擅長繁體中文理解，Dolphin模型則在程式設計和數學推理方面表現卓越，透過合併這兩個模型，我希望打造一個同時具備中文理解和程式設計能力的模型。

#### 3.1.2 模型部署概述

合併後的模型部署在Oracle Cloud Infrastructure的Ampere A1 Compute Instances上。在測試階段，使用llama.cpp和Langchain進行模型推理和與介面的串接。llama.cpp是一個基於C/C++的框架，用於LLM對話推理，Langchain則是一個開源框架，提供一系列工具和介面，方便開發者利用LLM。正式部署時，採用Ollama作為推理框架，Open WebUI提供互動介面。Ollama是一個開源框架，旨在讓使用者在本機環境中輕鬆執行和管理LLM，Open WebUI則是一個功能豐富且使用者友好的自託管WebUI，支援多種LLM執行庫，並提供了一個直觀的ChatGPT風格介面。

#### 3.1.3 整體系統架構

系統的整體架構包括前端UI、LLM模型和後端處理。前端UI負責接收使用者輸入，後端處理則負責將輸入傳遞給LLM模型，並將模型的輸出返回給使用者。

### 3.2 系統開發工具與實作

#### 3.2.1 LLM合併與量化：

模型合併採用Mergekit工具包，利用SLERP（球面線性插值）技術將Breeze和Dolphin模型的前32層進行合併。選擇前32層是為了保留兩個模型的基礎知識，並在後續層中融合更專門的任務知識。合併後的模型參數以bfloat16資料類型儲存，以提高計算效率。我在Google Colab上進行了模型合併，並詳細解釋了合併過程中使用的參數，包括模型切片、合併方法、標記器來源、基礎模型、參數和資料類型。

#### 3.2.2 前端UI開發與模型測試：

我在測試階段嘗試了Streamlit和Chainlit兩個Python框架來構建前端UI。Streamlit在構建UI方面較為簡便，但在實現token串流和對話紀錄復原功能時遇到了困難。Chainlit雖然功能較為陽春，但能夠儲存和復原對話紀錄，更適合用於測試LLM。

#### 3.2.3 UI測試之程式碼介紹：

我詳細介紹了Streamlit和Chainlit應用程式的程式碼。Streamlit部分的程式碼主要用於測試LLM的推理速度和結果，但未能實現token串流和對話紀錄復原功能。Chainlit部分的程式碼則透過模擬OpenAI的API伺服器，成功實現了對話紀錄的儲存和復原功能，驗證了合併模型BreezeDolphin的可行性。

### 3.3 系統介面展示：

我展示了Streamlit和Chainlit應用程式的介面。Chainlit應用程式在專題展示階段被用來展示模型的中文理解和程式設計能力，其介面包含歡迎訊息、輸入框、參數調整功能和對話紀錄的儲存與復原功能。雖然最終部署採用了功能更豐富的Open WebUI，但在專題展示階段，Chainlit應用程式成功驗證了合併模型BreezeDolphin的可行性和實用性。

## 4. 研究結果與討論

### 4.1 程式助手功能實測

在多次測試後，我發現合併 Breeze 和 Dolphin 模型後的 BreezeDolphin 程式助手展現出不錯的程式設計能力。透過在 Chainlit 應用程式中調整參數 temperature 為 0.4、top_p 為 0.5，助手能夠生成合理的程式碼回應。

然而，我也注意到一個明顯的問題：如果問題描述不夠清晰和詳細，BreezeDolphin 很容易給出錯誤或不完整的答案。即使偶爾答對了問題，它也經常忘記提供可以測試結果的函數。可以說它雖然是有用的，但卻經常遺漏。

以下將展示其中一個我詢問它程式碼問題的範例。所使用的程式碼問題來自於經典的背包問題（Knapsack problem），這是一個組合最佳化的 NP 完全問題，目標是在給定一組物品（每種物品都有各自的重量和價格）以及背包的總承重限制下，選擇價值總和最高的物品組合。

```python
def knapsack_problem(values, weights, capacity):
    n = len(values)
    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]

    for i in range(1, n + 1):
        for w in range(1, capacity + 1):
            if weights[i - 1] <= w:
                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weights[i - 1]], dp[i - 1][w])
            else:
                dp[i][w] = dp[i - 1][w]

    return dp[n][capacity]

values = [60, 100, 120]
weights = [10, 20, 30]
capacity = 50
max_value = knapsack_problem(values, weights, capacity)
print("Maximum value:", max_value)
```
以上是背包問題的 Python 解法範例，BreezeDolphin 針對該題目的回答如下：

```python
def knapsack(values, weights, capacity):
  n = len(values)
  dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]

  for i in range(1, n + 1):
    for w in range(1, capacity + 1):
      if weights[i - 1] <= w:
        dp[i][w] = max(values[i - 1] + dp[i - 1][w - weights[i - 1]], dp[i - 1][w])
      else:
        dp[i][w] = dp[i - 1][w]

  return dp[n][capacity]

values = [60, 100, 120]
weights = [10, 20, 30]
capacity = 50
print(knapsack(values, weights, capacity))  # Output: 220
```

可以看到，BreezeDolphin 生成的程式碼與標準解答幾乎相同，甚至更簡潔，答案也是正確的 220。然而，這也可能是因為背包問題是一個經典的演算法問題，模型可能在訓練過程中接觸過類似的資料。

為了進一步確認 BreezeDolphin 是否能勝任基礎的程式助手任務，我向 ChatGPT 要了一段含有錯誤的 Python 程式碼，用以考驗該模型：

```python
def is_prime(n):
  if n <= 1:
    return False
  for i in range(2, n):
    if n % i == 0:
      return True
  return False
```

這段程式碼的目的是判斷一個數是否為質數，但它有一個錯誤：當 n為質數時，它會返回 True，而正確的結果應該是 False。我將這段程式碼提交給 BreezeDolphin讓他分析，它的回答的中文翻譯如下：

```
這段程式碼的功能是判斷一個數是否為質數。
可以最佳化的地方：
1. 迴圈只需要到 n 的平方根即可，因為如果 n 有大於平方根的因數，那麼它也一定有小於平方根的因數。
2. 可以使用更快的質數判斷演算法，例如埃氏篩法或米勒-拉賓素性檢驗。
```
BreezeDolphin 並未指出程式碼的錯誤，而是建議如何提高演算法效率。這可能是因為 ChatGPT 生成的程式碼本身沒有語法錯誤，只是邏輯有誤。這顯示出 BreezeDolphin 在程式碼除錯方面的能力仍有待加強。

另外，在使用中文測試時，我觀察到 BreezeDolphin 對中文的理解能力仍有待提高。當我使用英文進行測試時，助手的表現變得更加出色和智慧。這個現象可能暗示了模型在中文語境下的理解和生成能力仍有提升空間。

整體來說，儘管 BreezeDolphin 展現出了一定的程式能力，但在中文理解和生成完整結果上的表現仍有改進空間。提高模型對問題描述的理解力，以及生成更連貫完整的答覆將是未來如果要持續探索這塊領域需要關注的重點。

## 5. 研究結論與建議

### 5.1 研究結論

本研究的初衷是開發一個能理解中文並應用於程式設計的語言模型助手。然而，由於資源和硬體的限制，我無法從頭訓練一個全新的模型，也無法對現有模型進行大規模的微調。因此，我選擇了合併現有的開源模型，並透過實作和測試來評估其效果。

具體來說，我選擇合併了兩個基於 Mistral 7B 的模型：Breeze 7B 和 Dolphin 2.6 Mistral 7b。Breeze 模型擅長繁體中文理解，而 Dolphin 模型則在程式設計和數學推理方面表現出色。透過 SLERP（球面線性插值）技術，我成功合併了這兩個模型，並將合併後的模型命名為 BreezeDolphin。

為了測試 BreezeDolphin 的效能，我開發了 Streamlit 和 Chainlit 兩個應用程式。Streamlit 應用程式主要用於測試模型的推理速度和結果，而 Chainlit 應用程式則更側重於展示模型的對話能力和參數調整功能。在測試過程中，我發現 BreezeDolphin 在程式設計方面表現良好，能夠生成合理的程式碼。然而，它在中文理解方面仍有改進空間，有時會產生不完整或不正確的回答。此外，模型在生成答案時經常遺漏可測試結果的函數，這也限制了其在實際應用中的效果。

儘管存在這些限制，但我認為 BreezeDolphin 仍是一個有潛力的程式助手。透過進一步的微調和最佳化，它有望在中文理解和程式設計方面取得更好的表現。

5.2 研究建議

基於本研究的發現和結論，我提出以下幾點建議，以期為未來的研究提供參考：

1.  **收集更多高品質的中文語料**：為了提高 BreezeDolphin 對中文的理解能力，建議收集更多高品質、多樣化的中文語料，特別是在程式設計領域的語料。這些語料可以用於對模型進行進一步的微調，使其更好地適應中文語境。
    
2.  **改進模型的生成能力**：BreezeDolphin 在生成完整和連貫的答案方面仍有不足，特別是經常遺漏可測試結果的函數。建議探索不同的微調策略或損失函數，以鼓勵模型生成更完整、更實用的答案。
    
3.  **嘗試更先進的模型架構和訓練方法**：Transformer 架構在自然語言處理領域取得了巨大的成功，但仍有很大的改進空間。可以嘗試探索其他更先進的模型架構，如 GPT-4 或 PaLM，並研究它們在中文程式設計領域的應用。
    
4.  **加強模型的評估**：除了 HumanEval 和 MBPP，還可以考慮使用其他評估標準來更全面地評估模型的效能。例如，可以設計一些更貼近實際應用場景的評估任務，如修復程式碼錯誤、生成單元測試等。
    
5.  **搭建更完善的開發環境**：本研究受到資源和硬體的限制，無法進行大規模的模型訓練和微調。如果有條件，可以考慮搭建更完善的開發環境，以便進行更深入的研究和實驗。
    

總之，本研究雖然取得了一定的成果，但仍有很大的改進空間。希望這些建議能為未來的研究提供一些啟發，推動中文語言模型在程式設計領域的發展。

## 6.附錄

**專題報告原檔(PDF版本):**
[連結](https://drive.google.com/file/d/1UFZ573_liLvevHafNUwg0yWOuwrkRau_/view?usp=sharing)

如果要觀看詳細的資料來源和更詳細的說明、展示的話都在報告中。

**專題發表影片(充滿口吃和停頓，不是很建議看):**
[連結](https://youtu.be/Nq_oD56Yl5o)

**BreezeDolphin-SLERP-0.1的線上聊天Live Demo:**
[連結](http//140.238.50.158:8501)

若無法使用請確認網址是否是http協定，而非https協定。
還是無法使用的話再聯絡我，或考慮參考以下網址自行架設。

**文中所提及的Chainlit WebUI的Github Repo:**
[連結](https://github.com/HsuanC0921/Chainlit_ChatLLM)

**BreezeDolphin-SLERP-0.1的HuggingFace Hub:**
[連結](https://huggingface.co/HsuanLLM/BreezeDolphin-SLERP-0.1)

**BreezeDolphin-SLERP-0.1的HuggingFace Hub (.GGUF量化版本):**
[連結](https://huggingface.co/HsuanLLM/BreezeDolphin-SLERP-0.1-GGUF)
